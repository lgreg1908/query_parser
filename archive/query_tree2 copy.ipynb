{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sqlparse\n",
    "from sqlparse.sql import Token, TokenList, IdentifierList, Identifier, Function, Comparison\n",
    "from sqlparse.tokens import DML, Whitespace, Keyword, Name, Literal\n",
    "\n",
    "from typing import List, Dict, Union, Optional\n",
    "from functools import lru_cache\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up basic logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_queries = [\n",
    "    \"UPDATE table SET column1 = 10\",\n",
    "    \"SELECT column FROM table\",\n",
    "    \"\"\"SELECT table.column1, table2.column2 FROM table JOIN (SELECT column2 FROM newtable) table2 ON table.column3 = table2.column3\"\"\",\n",
    "    \"\"\"\n",
    "    SELECT u.id, \n",
    "           (SELECT COUNT(*) FROM orders WHERE orders.user_id = u.id) as order_count,\n",
    "           (SELECT AVG(amount) FROM payments WHERE payments.user_id = u.id) as average_payment\n",
    "    FROM users u \n",
    "    WHERE u.registration_date BETWEEN '2020-01-01' AND '2020-12-31'\n",
    "    AND (u.status = 'active' OR u.id IN (SELECT user_id FROM vip_users));\"\"\"\n",
    "    ,\n",
    "    \"\"\"SELECT u.id\n",
    "    FROM users (select * from (select * from table))\"\"\",\n",
    "    \"ALTER TABLE table_name ADD column_name\",\n",
    "    \"\"\"\n",
    "    SELECT * FROM (\n",
    "        SELECT col1 FROM table1\n",
    "        UNION\n",
    "        SELECT col2 FROM table2\n",
    "    ) AS subquery\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    WITH cte AS (\n",
    "        SELECT col1 FROM table1\n",
    "        UNION\n",
    "        SELECT col2 FROM table2\n",
    "    )\n",
    "    SELECT * FROM cte\n",
    "    \"\"\",\n",
    "    \"SELECT *    FROM    my_table WHERE   id = 1\"\n",
    "    \n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QueryNormalizer:\n",
    "    def normalize_query(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        Normalizes the SQL query by formatting.\n",
    "\n",
    "        :param query: Raw SQL query string.\n",
    "        :return: Normalized SQL query string.\n",
    "        \"\"\"\n",
    "        return sqlparse.format(query, reindent=True, keyword_case='upper', strip_whitespace=True) if query else ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryParser:\n",
    "    def parse_query(self, query: str) -> List[Token]:\n",
    "        \"\"\"\n",
    "        Parses the SQL query and creates a parse tree.\n",
    "\n",
    "        :param query: SQL query string.\n",
    "        :return: List of Tokens representing the parse tree.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            parsed = sqlparse.parse(query)\n",
    "            if not parsed:\n",
    "                logger.error(\"Failed to parse the query\")\n",
    "                raise ValueError(\"Failed to parse the query\")\n",
    "\n",
    "            return parsed[0].tokens\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error while parsing the query: {e}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryAnalyzer:\n",
    "    def is_read_only(self, tokens: List[Token]) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if the given tokens represent a read-only (SELECT) SQL query.\n",
    "\n",
    "        :param tokens: List of Tokens representing the SQL query.\n",
    "        :return: Boolean indicating if the query is read-only.\n",
    "        \"\"\"\n",
    "        modifying_keywords = [\"INSERT\", \"UPDATE\", \"DELETE\", \"DROP\", \"ALTER\"]\n",
    "        flat_tokens = [token.normalized for token in tokens if not isinstance(token, TokenList)]\n",
    "        return not any(keyword in flat_tokens for keyword in modifying_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqlQuery:\n",
    "    def __init__(self, query: Optional[str] = None, normalizer: QueryNormalizer = QueryNormalizer(),\n",
    "                 parser: QueryParser = QueryParser(), analyzer: QueryAnalyzer = QueryAnalyzer()):\n",
    "        \"\"\"\n",
    "        Initialize the SqlQuery class with an optional SQL query.\n",
    "\n",
    "        :param query: Raw SQL query string.\n",
    "        :param normalizer: Instance of QueryNormalizer.\n",
    "        :param parser: Instance of QueryParser.\n",
    "        :param analyzer: Instance of QueryAnalyzer.\n",
    "        \"\"\"\n",
    "        self.raw_query = query\n",
    "        self.normalized_query = normalizer.normalize_query(query) if query else None\n",
    "        self.tree: Optional[List[Token]] = None\n",
    "        self.parser = parser\n",
    "        self.analyzer = analyzer\n",
    "\n",
    "    def set_query(self, query: str, normalize: bool = True):\n",
    "        \"\"\"\n",
    "        Sets a new SQL query and optionally normalizes it.\n",
    "\n",
    "        :param query: Raw SQL query string.\n",
    "        :param normalize: Boolean flag to normalize the query.\n",
    "        \"\"\"\n",
    "        self.raw_query = query\n",
    "        self.normalized_query = self.normalizer.normalize_query(query) if normalize else query\n",
    "        self.tree = None\n",
    "\n",
    "    def create_tree(self) -> List[Token]:\n",
    "        \"\"\"\n",
    "        Parses the SQL query (normalized, if available) and creates a parse tree.\n",
    "\n",
    "        :return: List of Tokens representing the parse tree.\n",
    "        \"\"\"\n",
    "        query_to_parse = self.normalized_query if self.normalized_query else self.raw_query\n",
    "        if not query_to_parse:\n",
    "            logger.error(\"No query set\")\n",
    "            raise ValueError(\"No query set\")\n",
    "\n",
    "        self.tree = self.parser.parse_query(query_to_parse)\n",
    "        return self.tree\n",
    "\n",
    "    def is_read_only(self) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if the set query is read-only (SELECT).\n",
    "\n",
    "        :return: Boolean indicating if the query is read-only.\n",
    "        \"\"\"\n",
    "        if not self.tree:\n",
    "            logger.error(\"Parse tree is not set\")\n",
    "            raise ValueError(\"Parse tree is not set\")\n",
    "\n",
    "        return self.analyzer.is_read_only(self.tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List, Union, Dict\n",
    "import sqlparse\n",
    "from sqlparse.tokens import Token, TokenList\n",
    "from functools import lru_cache\n",
    "\n",
    "class QueryNormalizer:\n",
    "    def normalize_query(self, query: str) -> str:\n",
    "        return sqlparse.format(query, reindent=True, keyword_case='upper', strip_whitespace=True) if query else ''\n",
    "\n",
    "\n",
    "class QueryParser:\n",
    "    def parse_query(self, query: str) -> List[Token]:\n",
    "        try:\n",
    "            parsed = sqlparse.parse(query)\n",
    "            if not parsed:\n",
    "                logger.error(\"Failed to parse the query\")\n",
    "                raise ValueError(\"Failed to parse the query\")\n",
    "            return parsed[0].tokens\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error while parsing the query: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "class TokenProcessor:\n",
    "    def process(self, token) -> Union[Dict, str, None]:\n",
    "        if token.is_group:\n",
    "            children = [self.process(child) for child in token.tokens]\n",
    "            return {\n",
    "                \"type\": type(token).__name__,\n",
    "                \"value\": token.normalized,\n",
    "                \"children\": [c for c in children if c]\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"type\": token.ttype,\n",
    "                \"value\": token.normalized\n",
    "            }\n",
    "\n",
    "\n",
    "class SqlQuery:\n",
    "    def __init__(self, query: Optional[str] = None, normalizer: QueryNormalizer = QueryNormalizer(),\n",
    "                 parser: QueryParser = QueryParser(), token_processor: TokenProcessor = TokenProcessor()):\n",
    "        self.raw_query = query\n",
    "        self.normalized_query = normalizer.normalize_query(query) if query else None\n",
    "        self.tree: Optional[List[Token]] = None\n",
    "        self.parser = parser\n",
    "        self.token_processor = token_processor\n",
    "\n",
    "    def set_query(self, query: str, normalize: bool = True):\n",
    "        self.raw_query = query\n",
    "        self.normalized_query = self.normalizer.normalize_query(query) if normalize else query\n",
    "        self.tree = None\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def create_tree(self) -> List[Token]:\n",
    "        query_to_parse = self.normalized_query if self.normalized_query else self.raw_query\n",
    "        if not query_to_parse:\n",
    "            logger.error(\"No query set\")\n",
    "            raise ValueError(\"No query set\")\n",
    "\n",
    "        try:\n",
    "            parsed = self.parser.parse_query(query_to_parse)\n",
    "            if not parsed:\n",
    "                logger.error(\"Failed to parse the query\")\n",
    "                raise ValueError(\"Failed to parse the query\")\n",
    "\n",
    "            self.tree = parsed\n",
    "            return self.tree\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error while parsing the query: {e}\")\n",
    "            raise\n",
    "\n",
    "    def flatten_tree(self, tokens: Optional[List[Token]] = None) -> List[str]:\n",
    "        if tokens is None:\n",
    "            tokens = self.tree\n",
    "\n",
    "        if tokens is None:\n",
    "            logger.error(\"Parse tree is not set\")\n",
    "            raise ValueError(\"Parse tree is not set\")\n",
    "\n",
    "        flat_tokens = []\n",
    "        for token in tokens:\n",
    "            if isinstance(token, TokenList):\n",
    "                flat_tokens.extend(self.flatten_tree(token.tokens))\n",
    "            else:\n",
    "                flat_tokens.append(token.normalized)\n",
    "        return flat_tokens\n",
    "\n",
    "    def tree_to_dict(self, tokens=None) -> Dict:\n",
    "        if tokens is None:\n",
    "            tokens = self.tree\n",
    "\n",
    "        return {\"type\": \"ROOT\", \"children\": [self.token_processor.process(token) for token in tokens if self.token_processor.process(token)]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QueryProcessor:\n",
    "    def __init__(self, query: str):\n",
    "        self.query = query\n",
    "\n",
    "    def normalize_query(self) -> str:\n",
    "        return sqlparse.format(self.query, reindent=True, keyword_case='upper', strip_whitespace=True)\n",
    "\n",
    "    def parse_query(self) -> List[Token]:\n",
    "        try:\n",
    "            parsed = sqlparse.parse(self.query)\n",
    "            if not parsed:\n",
    "                raise ValueError(\"Failed to parse the query\")\n",
    "            return parsed[0].tokens\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error while parsing the query: {e}\")\n",
    "\n",
    "class TokenProcessor:\n",
    "    def process(self, tokens: List[Token]) -> List[Dict]:\n",
    "        result = []\n",
    "        for token in tokens:\n",
    "            if isinstance(token, TokenList):\n",
    "                children = self.process(token.tokens)\n",
    "                result.append({\n",
    "                    \"type\": type(token).__name__,\n",
    "                    \"value\": token.normalized,\n",
    "                    \"children\": children\n",
    "                })\n",
    "            else:\n",
    "                result.append({\n",
    "                    \"type\": token.ttype,\n",
    "                    \"value\": token.normalized\n",
    "                })\n",
    "        return result\n",
    "\n",
    "class SqlQuery:\n",
    "    def __init__(self):\n",
    "        self.raw_query = None\n",
    "        self.normalized_query = None\n",
    "        self.tree: Optional[List[Token]] = None\n",
    "\n",
    "    def set_query(self, query: str, normalize: bool = True):\n",
    "        self.clear_cache()\n",
    "        self.raw_query = query\n",
    "        if normalize:\n",
    "            processor = QueryProcessor(query)\n",
    "            self.normalized_query = processor.normalize_query()\n",
    "            self.tree = None\n",
    "        else:\n",
    "            processor = QueryProcessor(query)\n",
    "            self.tree = processor.parse_query()\n",
    "            self.normalized_query = None\n",
    "            \n",
    "    @lru_cache(maxsize=None)\n",
    "    def create_tree(self) -> List[Token]:\n",
    "        if not self.raw_query:\n",
    "            raise ValueError(\"No query set\")\n",
    "\n",
    "        if self.tree is None:\n",
    "            processor = QueryProcessor(self.raw_query)\n",
    "            self.tree = processor.parse_query()\n",
    "\n",
    "        return self.tree\n",
    "\n",
    "    def clear_cache(self):\n",
    "        \"\"\"\n",
    "        Clear the LRU cache used for create_tree.\n",
    "        \"\"\"\n",
    "        self.create_tree.cache_clear()\n",
    "\n",
    "    def flatten_tree(self, tokens: Optional[List[Token]] = None) -> List[str]:\n",
    "        if tokens is None:\n",
    "            tokens = self.create_tree()\n",
    "\n",
    "        flat_tokens = []\n",
    "        for token in tokens:\n",
    "            if isinstance(token, TokenList):\n",
    "                flat_tokens.extend(self.flatten_tree(token.tokens))\n",
    "            else:\n",
    "                flat_tokens.append(token.normalized)\n",
    "        return flat_tokens\n",
    "\n",
    "    def tree_to_dict(self, tokens=None) -> Dict:\n",
    "        if tokens is None:\n",
    "            tokens = self.create_tree()\n",
    "\n",
    "        token_processor = TokenProcessor()\n",
    "        return {\"type\": \"ROOT\", \"children\": token_processor.process(tokens)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QueryProcessor:\n",
    "    def __init__(self, query: str):\n",
    "        self.query = query\n",
    "\n",
    "    def normalize_query(self) -> str:\n",
    "        try:\n",
    "            return sqlparse.format(self.query, reindent=True, keyword_case='upper', strip_whitespace=True)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error while normalizing the query: {e}\")\n",
    "\n",
    "    def parse_query(self) -> List[Token]:\n",
    "        try:\n",
    "            parsed = sqlparse.parse(self.query)\n",
    "            if not parsed:\n",
    "                raise ValueError(\"Failed to parse the query\")\n",
    "            return parsed[0].tokens\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error while parsing the query: {e}\")\n",
    "\n",
    "class TokenProcessor:\n",
    "    def process(self, tokens: List[Token]) -> List[Dict]:\n",
    "        result = []\n",
    "        for token in tokens:\n",
    "            if isinstance(token, TokenList):\n",
    "                children = self.process(token.tokens)\n",
    "                result.append({\n",
    "                    \"type\": type(token).__name__,\n",
    "                    \"value\": token.normalized,\n",
    "                    \"children\": children\n",
    "                })\n",
    "            else:\n",
    "                result.append({\n",
    "                    \"type\": token.ttype,\n",
    "                    \"value\": token.normalized\n",
    "                })\n",
    "        return result\n",
    "\n",
    "class SqlQuery:\n",
    "    def __init__(self):\n",
    "        self.raw_query = None\n",
    "        self.normalized_query = None\n",
    "        self.tree: Optional[List[Token]] = None\n",
    "\n",
    "    def set_query(self, query: str, normalize: bool = True):\n",
    "        self.clear_cache()  # Clear the cache before processing a new query.\n",
    "        if not query:\n",
    "            raise ValueError(\"Query cannot be empty\")\n",
    "        self.raw_query = query\n",
    "        if normalize:\n",
    "            processor = QueryProcessor(query)\n",
    "            self.normalized_query = processor.normalize_query()\n",
    "            self.tree = None\n",
    "        else:\n",
    "            processor = QueryProcessor(query)\n",
    "            self.tree = processor.parse_query()\n",
    "            self.normalized_query = None\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def create_tree(self) -> List[Token]:\n",
    "        if not self.raw_query:\n",
    "            raise ValueError(\"No query set\")\n",
    "\n",
    "        if self.tree is None:\n",
    "            processor = QueryProcessor(self.raw_query)\n",
    "            self.tree = processor.parse_query()\n",
    "\n",
    "        return self.tree\n",
    "\n",
    "    def clear_cache(self):\n",
    "        \"\"\"\n",
    "        Clear the LRU cache used for create_tree.\n",
    "        \"\"\"\n",
    "        self.create_tree.cache_clear()\n",
    "\n",
    "    def flatten_tree(self, tokens: Optional[List[Token]] = None) -> List[str]:\n",
    "        if tokens is None:\n",
    "            tokens = self.create_tree()\n",
    "\n",
    "        flat_tokens = []\n",
    "        for token in tokens:\n",
    "            if isinstance(token, TokenList):\n",
    "                flat_tokens.extend(self.flatten_tree(token.tokens))\n",
    "            else:\n",
    "                flat_tokens.append(token.normalized)\n",
    "        return flat_tokens\n",
    "\n",
    "    def tree_to_dict(self, tokens=None) -> Dict:\n",
    "        if tokens is None:\n",
    "            tokens = self.create_tree()\n",
    "\n",
    "        token_processor = TokenProcessor()\n",
    "        return {\"type\": \"ROOT\", \"children\": token_processor.process(tokens)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class QueryProcessor:\n",
    "    def __init__(self, query: str):\n",
    "        self.query = query\n",
    "\n",
    "    def normalize_query(self) -> str:\n",
    "        try:\n",
    "            return sqlparse.format(self.query, reindent=True, keyword_case='upper', strip_whitespace=True)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error while normalizing the query: {e}\")\n",
    "\n",
    "    def parse_query(self) -> List[Token]:\n",
    "        try:\n",
    "            parsed = sqlparse.parse(self.query)\n",
    "            if not parsed:\n",
    "                raise ValueError(\"Failed to parse the query\")\n",
    "            return parsed[0].tokens\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error while parsing the query: {e}\")\n",
    "\n",
    "class TokenProcessor:\n",
    "    def process(self, tokens: List[Token]) -> List[Dict]:\n",
    "        result = []\n",
    "        for token in tokens:\n",
    "            if isinstance(token, TokenList):\n",
    "                children = self.process(token.tokens)\n",
    "                result.append({\n",
    "                    \"type\": type(token).__name__,\n",
    "                    \"value\": token.normalized,\n",
    "                    \"is_group\": True,  # Add the is_group tag.\n",
    "                    \"children\": children\n",
    "                })\n",
    "            else:\n",
    "                result.append({\n",
    "                    \"type\": token.ttype,\n",
    "                    \"value\": token.normalized,\n",
    "                    \"is_group\": False  # Add the is_group tag.\n",
    "                })\n",
    "        return result\n",
    "\n",
    "class SqlQuery:\n",
    "    def __init__(self):\n",
    "        self.raw_query = None\n",
    "        self.normalized_query = None\n",
    "        self.tree: Optional[List[Token]] = None\n",
    "\n",
    "    def set_query(self, query: str, normalize: bool = True):\n",
    "        self.clear_cache()  # Clear the cache before processing a new query.\n",
    "        if not query:\n",
    "            raise ValueError(\"Query cannot be empty\")\n",
    "        self.raw_query = query\n",
    "        if normalize:\n",
    "            processor = QueryProcessor(query)\n",
    "            self.normalized_query = processor.normalize_query()\n",
    "            self.tree = None\n",
    "        else:\n",
    "            processor = QueryProcessor(query)\n",
    "            self.tree = processor.parse_query()\n",
    "            self.normalized_query = None\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def create_tree(self) -> List[Token]:\n",
    "        if not self.raw_query:\n",
    "            raise ValueError(\"No query set\")\n",
    "\n",
    "        if self.tree is None:\n",
    "            processor = QueryProcessor(self.raw_query)\n",
    "            self.tree = processor.parse_query()\n",
    "\n",
    "        return self.tree\n",
    "\n",
    "    def clear_cache(self):\n",
    "        \"\"\"\n",
    "        Clear the LRU cache used for create_tree.\n",
    "        \"\"\"\n",
    "        self.create_tree.cache_clear()\n",
    "\n",
    "    def flatten_tree(self, tokens: Optional[List[Token]] = None) -> List[str]:\n",
    "        if tokens is None:\n",
    "            tokens = self.create_tree()\n",
    "\n",
    "        flat_tokens = []\n",
    "        for token in tokens:\n",
    "            if isinstance(token, TokenList):\n",
    "                flat_tokens.extend(self.flatten_tree(token.tokens))\n",
    "            else:\n",
    "                flat_tokens.append(token.normalized)\n",
    "        return flat_tokens\n",
    "\n",
    "    def tree_to_dict(self, tokens=None) -> Dict:\n",
    "        if tokens is None:\n",
    "            tokens = self.create_tree()\n",
    "\n",
    "        token_processor = TokenProcessor()\n",
    "        return {\"type\": \"ROOT\", \"children\": token_processor.process(tokens)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = SqlQuery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.set_query(sql_queries[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'ROOT',\n",
       " 'children': [{'type': Token.Text.Whitespace.Newline,\n",
       "   'value': '\\n',\n",
       "   'is_group': False},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "  {'type': Token.Keyword.DML, 'value': 'SELECT', 'is_group': False},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "  {'type': Token.Wildcard, 'value': '*', 'is_group': False},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "  {'type': Token.Keyword, 'value': 'FROM', 'is_group': False},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "  {'type': 'Identifier',\n",
       "   'value': '(\\n        SELECT col1 FROM table1\\n        UNION\\n        SELECT col2 FROM table2\\n    ) AS subquery',\n",
       "   'is_group': True,\n",
       "   'children': [{'type': 'Parenthesis',\n",
       "     'value': '(\\n        SELECT col1 FROM table1\\n        UNION\\n        SELECT col2 FROM table2\\n    )',\n",
       "     'is_group': True,\n",
       "     'children': [{'type': Token.Punctuation, 'value': '(', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace.Newline,\n",
       "       'value': '\\n',\n",
       "       'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Keyword.DML, 'value': 'SELECT', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': 'Identifier',\n",
       "       'value': 'col1',\n",
       "       'is_group': True,\n",
       "       'children': [{'type': Token.Name, 'value': 'col1', 'is_group': False}]},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Keyword, 'value': 'FROM', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': 'Identifier',\n",
       "       'value': 'table1',\n",
       "       'is_group': True,\n",
       "       'children': [{'type': Token.Name,\n",
       "         'value': 'table1',\n",
       "         'is_group': False}]},\n",
       "      {'type': Token.Text.Whitespace.Newline,\n",
       "       'value': '\\n',\n",
       "       'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Keyword, 'value': 'UNION', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace.Newline,\n",
       "       'value': '\\n',\n",
       "       'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Keyword.DML, 'value': 'SELECT', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': 'Identifier',\n",
       "       'value': 'col2',\n",
       "       'is_group': True,\n",
       "       'children': [{'type': Token.Name, 'value': 'col2', 'is_group': False}]},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Keyword, 'value': 'FROM', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': 'Identifier',\n",
       "       'value': 'table2',\n",
       "       'is_group': True,\n",
       "       'children': [{'type': Token.Name,\n",
       "         'value': 'table2',\n",
       "         'is_group': False}]},\n",
       "      {'type': Token.Text.Whitespace.Newline,\n",
       "       'value': '\\n',\n",
       "       'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "      {'type': Token.Punctuation, 'value': ')', 'is_group': False}]},\n",
       "    {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "    {'type': Token.Keyword, 'value': 'AS', 'is_group': False},\n",
       "    {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "    {'type': 'Identifier',\n",
       "     'value': 'subquery',\n",
       "     'is_group': True,\n",
       "     'children': [{'type': Token.Name,\n",
       "       'value': 'subquery',\n",
       "       'is_group': False}]}]},\n",
       "  {'type': Token.Text.Whitespace.Newline, 'value': '\\n', 'is_group': False},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' ', 'is_group': False}]}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.tree_to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QueryProcessor:\n",
    "    def __init__(self, query: str):\n",
    "        self.query = query\n",
    "\n",
    "    def normalize_query(self) -> str:\n",
    "        try:\n",
    "            return sqlparse.format(self.query, reindent=True, keyword_case='upper', strip_whitespace=True)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error while normalizing the query: {e}\")\n",
    "\n",
    "    def parse_query(self) -> List[Token]:\n",
    "        try:\n",
    "            parsed = sqlparse.parse(self.query)\n",
    "            if not parsed:\n",
    "                raise ValueError(\"Failed to parse the query\")\n",
    "            return parsed[0].tokens\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error while parsing the query: {e}\")\n",
    "\n",
    "class TokenProcessor:\n",
    "    def process(self, tokens: List[Token]) -> List[Dict]:\n",
    "        result = []\n",
    "        for token in tokens:\n",
    "            if isinstance(token, TokenList):\n",
    "                children = self.process(token.tokens)\n",
    "                result.append({\n",
    "                    \"type\": type(token).__name__,\n",
    "                    \"value\": token,\n",
    "                    \"is_group\": True,  # Add the is_group tag.\n",
    "                    \"children\": children\n",
    "                })\n",
    "            else:\n",
    "                result.append({\n",
    "                    \"type\": token.ttype,\n",
    "                    \"value\": token,\n",
    "                    \"is_group\": False  # Add the is_group tag.\n",
    "                })\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "class SqlQuery:\n",
    "    def __init__(self, query: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize the SqlQuery class with an optional SQL query.\n",
    "\n",
    "        :param query: Raw SQL query string.\n",
    "        \"\"\"\n",
    "        self._raw_query = query\n",
    "        self._normalized_query = self._normalize_query(query) if query else None\n",
    "        self._tree: Optional[List[Token]] = None\n",
    "        self._parsed_query: Optional[Token] = None\n",
    "\n",
    "    @property\n",
    "    def raw_query(self):\n",
    "        return self._raw_query\n",
    "\n",
    "    @raw_query.setter\n",
    "    def raw_query(self, query):\n",
    "        self.clear_cache()\n",
    "        self._raw_query = query\n",
    "\n",
    "    @property\n",
    "    def normalized_query(self):\n",
    "        if not self._normalized_query:\n",
    "            self._normalized_query = self._normalize_query(self._raw_query) if self._raw_query else ''\n",
    "        return self._normalized_query\n",
    "\n",
    "    def clear_cache(self):\n",
    "        \"\"\"\n",
    "        Clear the LRU caches used for tree_dict, flatten_tree, and flatten_dict_tree.\n",
    "        \"\"\"\n",
    "        self.tree_dict.cache_clear()\n",
    "        self.flatten_tree.cache_clear()\n",
    "        self.flatten_dict_tree.cache_clear()\n",
    "\n",
    "    def _normalize_query(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        Normalizes the SQL query by formatting.\n",
    "\n",
    "        :param query: Raw SQL query string.\n",
    "        :return: Normalized SQL query string.\n",
    "        \"\"\"\n",
    "        return sqlparse.format(query, reindent=True, keyword_case='upper', strip_whitespace=True) if query else ''\n",
    "\n",
    "    def set_query(self, query: str, normalize: bool = True):\n",
    "        \"\"\"\n",
    "        Sets a new SQL query and optionally normalizes it.\n",
    "\n",
    "        :param query: Raw SQL query string.\n",
    "        :param normalize: Boolean flag to normalize the query.\n",
    "        \"\"\"\n",
    "        self._raw_query = query\n",
    "        if normalize:\n",
    "            self._normalized_query = self._normalize_query(query)\n",
    "        else:\n",
    "            self._normalized_query = query\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def create_tree(self) -> List[Token]:\n",
    "        \"\"\"\n",
    "        Parses the SQL query (normalized, if available) and creates a parse tree.\n",
    "\n",
    "        :return: List of Tokens representing the parse tree.\n",
    "        \"\"\"\n",
    "        query_to_parse = self.normalized_query if self.normalized_query else self.raw_query\n",
    "        if not query_to_parse:\n",
    "            raise ValueError(\"No query set\")\n",
    "\n",
    "        try:\n",
    "            parsed = sqlparse.parse(query_to_parse)\n",
    "            if not parsed:\n",
    "                raise ValueError(\"Failed to parse the query\")\n",
    "\n",
    "            self._parsed_query = parsed[0]\n",
    "            self._tree = self._parsed_query.tokens\n",
    "            return self._tree\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error while parsing the query: {e}\")\n",
    "\n",
    "    @property\n",
    "    def tree(self):\n",
    "        if not self._tree:\n",
    "            self.create_tree()\n",
    "        return self._tree\n",
    "\n",
    "    def tree_to_dict(self, tokens=None) -> Dict:\n",
    "        \"\"\"\n",
    "        Converts a list of SQL tokens to a nested dictionary representation.\n",
    "\n",
    "        :param tokens: List of SQL tokens.\n",
    "        :return: Nested dictionary representing the SQL tokens.\n",
    "        \"\"\"\n",
    "        if tokens is None:\n",
    "            tokens = self.tree\n",
    "\n",
    "        result = {\n",
    "            \"type\": \"ROOT\",\n",
    "            \"children\": [self._process_token(token) for token in tokens if self._process_token(token)]\n",
    "        }\n",
    "        return result\n",
    "\n",
    "    def flatten_tree(self, tokens: Optional[List[Token]] = None) -> List[str]:\n",
    "        \"\"\"\n",
    "        Flattens the parse tree to a list of token strings.\n",
    "\n",
    "        :param tokens: Optional list of tokens to flatten.\n",
    "        :return: List of strings representing flattened tokens.\n",
    "        \"\"\"\n",
    "        if tokens is None:\n",
    "            tokens = self.tree\n",
    "\n",
    "        flat_tokens = []\n",
    "        for token in tokens:\n",
    "            if isinstance(token, TokenList):\n",
    "                flat_tokens.extend(self.flatten_tree(token.tokens))\n",
    "            else:\n",
    "                flat_tokens.append(token.normalized)\n",
    "        return flat_tokens\n",
    "\n",
    "    def flatten_dict_tree(self, tokens=None) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Flattens the parse tree to a list of dictionaries.\n",
    "\n",
    "        :param tokens: List of SQL tokens.\n",
    "        :return: List of dictionaries representing flattened tokens.\n",
    "        \"\"\"\n",
    "        if tokens is None:\n",
    "            tokens = self.tree\n",
    "\n",
    "        flat_tokens = []\n",
    "        for token in tokens:\n",
    "            flat_tokens.append(self._process_token(token))\n",
    "        return flat_tokens\n",
    "\n",
    "    def _process_token(self, token) -> Union[Dict, str, None]:\n",
    "        \"\"\"\n",
    "        Process a single SQL token into a dictionary representation.\n",
    "\n",
    "        :param token: The SQL token to process.\n",
    "        :return: A dictionary representation of the token, or None for whitespace.\n",
    "        \"\"\"\n",
    "        if isinstance(token, TokenList):\n",
    "            children = [self._process_token(child) for child in token.tokens]\n",
    "            return {\n",
    "                \"type\": type(token).__name__,\n",
    "                \"value\": token.normalized,\n",
    "                \"children\": [c for c in children if c]\n",
    "            }\n",
    "        elif not isinstance(token, Whitespace):\n",
    "            return {\n",
    "                \"type\": token.ttype,\n",
    "                \"value\": token.normalized\n",
    "            }\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    @lru_cache(maxsize=None)\n",
    "    def tree_dict(self):\n",
    "        return self.tree_to_dict()\n",
    "\n",
    "    @property\n",
    "    @lru_cache(maxsize=None)\n",
    "    def flatten_tree(self):\n",
    "        return self.flatten_tree()\n",
    "\n",
    "    @property\n",
    "    @lru_cache(maxsize=None)\n",
    "    def flatten_dict_tree(self):\n",
    "        return self.flatten_dict_tree()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = SqlQuery(sql_queries[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No query set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [97]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m query\u001b[38;5;241m.\u001b[39mraw_query \u001b[38;5;241m=\u001b[39m  sql_queries[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m]\n",
      "Input \u001b[0;32mIn [95]\u001b[0m, in \u001b[0;36mSqlQuery.raw_query\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;129m@raw_query\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraw_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, query):\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclear_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_query \u001b[38;5;241m=\u001b[39m query\n",
      "Input \u001b[0;32mIn [95]\u001b[0m, in \u001b[0;36mSqlQuery.clear_cache\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclear_cache\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    Clear the LRU caches used for tree_dict, flatten_tree, and flatten_dict_tree.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_dict\u001b[49m\u001b[38;5;241m.\u001b[39mcache_clear()\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten_tree\u001b[38;5;241m.\u001b[39mcache_clear()\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten_dict_tree\u001b[38;5;241m.\u001b[39mcache_clear()\n",
      "Input \u001b[0;32mIn [95]\u001b[0m, in \u001b[0;36mSqlQuery.tree_dict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m(maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtree_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_to_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [95]\u001b[0m, in \u001b[0;36mSqlQuery.tree_to_dict\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03mConverts a list of SQL tokens to a nested dictionary representation.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m:param tokens: List of SQL tokens.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m:return: Nested dictionary representing the SQL tokens.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree\u001b[49m\n\u001b[1;32m    137\u001b[0m result \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROOT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchildren\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_token(token) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_token(token)]\n\u001b[1;32m    140\u001b[0m }\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Input \u001b[0;32mIn [95]\u001b[0m, in \u001b[0;36mSqlQuery.tree\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtree\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tree:\n\u001b[0;32m--> 124\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tree\n",
      "Input \u001b[0;32mIn [95]\u001b[0m, in \u001b[0;36mSqlQuery.create_tree\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m query_to_parse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalized_query \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalized_query \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_query\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m query_to_parse:\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo query set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m     parsed \u001b[38;5;241m=\u001b[39m sqlparse\u001b[38;5;241m.\u001b[39mparse(query_to_parse)\n",
      "\u001b[0;31mValueError\u001b[0m: No query set"
     ]
    }
   ],
   "source": [
    "query.raw_query =  sql_queries[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "isinstance() arg 2 must be a type or tuple of types",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [99]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_to_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [95]\u001b[0m, in \u001b[0;36mSqlQuery.tree_to_dict\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree\n\u001b[1;32m    137\u001b[0m result \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROOT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchildren\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_token(token) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_token(token)]\n\u001b[1;32m    140\u001b[0m }\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Input \u001b[0;32mIn [95]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree\n\u001b[1;32m    137\u001b[0m result \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROOT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchildren\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_token(token) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    140\u001b[0m }\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Input \u001b[0;32mIn [95]\u001b[0m, in \u001b[0;36mSqlQuery._process_token\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m    184\u001b[0m     children \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_token(child) \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m token\u001b[38;5;241m.\u001b[39mtokens]\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(token)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: token\u001b[38;5;241m.\u001b[39mnormalized,\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchildren\u001b[39m\u001b[38;5;124m\"\u001b[39m: [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m children \u001b[38;5;28;01mif\u001b[39;00m c]\n\u001b[1;32m    189\u001b[0m     }\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWhitespace\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: token\u001b[38;5;241m.\u001b[39mttype,\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: token\u001b[38;5;241m.\u001b[39mnormalized\n\u001b[1;32m    194\u001b[0m     }\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: isinstance() arg 2 must be a type or tuple of types"
     ]
    }
   ],
   "source": [
    "query.tree_to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'SELECT',\n",
       " ' ',\n",
       " '*',\n",
       " ' ',\n",
       " 'FROM',\n",
       " ' ',\n",
       " '(',\n",
       " '\\n',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'SELECT',\n",
       " ' ',\n",
       " 'col1',\n",
       " ' ',\n",
       " 'FROM',\n",
       " ' ',\n",
       " 'table1',\n",
       " '\\n',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'UNION',\n",
       " '\\n',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'SELECT',\n",
       " ' ',\n",
       " 'col2',\n",
       " ' ',\n",
       " 'FROM',\n",
       " ' ',\n",
       " 'table2',\n",
       " '\\n',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ')',\n",
       " ' ',\n",
       " 'AS',\n",
       " ' ',\n",
       " 'subquery',\n",
       " '\\n',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.flatten_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'ROOT',\n",
       " 'children': [{'type': Token.Text.Whitespace.Newline, 'value': '\\n'},\n",
       "  {'type': Token.Keyword.DML, 'value': 'SELECT'},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "  {'type': Token.Wildcard, 'value': '*'},\n",
       "  {'type': Token.Text.Whitespace.Newline, 'value': '\\n'},\n",
       "  {'type': Token.Keyword, 'value': 'FROM'},\n",
       "  {'type': Token.Text.Whitespace.Newline, 'value': '\\n'},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "  {'type': 'Identifier',\n",
       "   'value': '(SELECT col1\\n   FROM table1\\n   UNION SELECT col2\\n   FROM table2) AS subquery',\n",
       "   'children': [{'type': 'Parenthesis',\n",
       "     'value': '(SELECT col1\\n   FROM table1\\n   UNION SELECT col2\\n   FROM table2)',\n",
       "     'children': [{'type': Token.Punctuation, 'value': '('},\n",
       "      {'type': Token.Keyword.DML, 'value': 'SELECT'},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "      {'type': 'Identifier',\n",
       "       'value': 'col1',\n",
       "       'children': [{'type': Token.Name, 'value': 'col1'}]},\n",
       "      {'type': Token.Text.Whitespace.Newline, 'value': '\\n'},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "      {'type': Token.Keyword, 'value': 'FROM'},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "      {'type': 'Identifier',\n",
       "       'value': 'table1',\n",
       "       'children': [{'type': Token.Name, 'value': 'table1'}]},\n",
       "      {'type': Token.Text.Whitespace.Newline, 'value': '\\n'},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "      {'type': Token.Keyword, 'value': 'UNION'},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "      {'type': Token.Keyword.DML, 'value': 'SELECT'},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "      {'type': 'Identifier',\n",
       "       'value': 'col2',\n",
       "       'children': [{'type': Token.Name, 'value': 'col2'}]},\n",
       "      {'type': Token.Text.Whitespace.Newline, 'value': '\\n'},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "      {'type': Token.Keyword, 'value': 'FROM'},\n",
       "      {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "      {'type': 'Identifier',\n",
       "       'value': 'table2',\n",
       "       'children': [{'type': Token.Name, 'value': 'table2'}]},\n",
       "      {'type': Token.Punctuation, 'value': ')'}]},\n",
       "    {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "    {'type': Token.Keyword, 'value': 'AS'},\n",
       "    {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "    {'type': 'Identifier',\n",
       "     'value': 'subquery',\n",
       "     'children': [{'type': Token.Name, 'value': 'subquery'}]}]}]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.tree_to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'ROOT',\n",
       " 'children': [{'type': Token.Keyword.DML, 'value': 'UPDATE'},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "  {'type': Token.Keyword, 'value': 'TABLE'},\n",
       "  {'type': Token.Text.Whitespace.Newline, 'value': '\\n'},\n",
       "  {'type': Token.Keyword, 'value': 'SET'},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "  {'type': 'Comparison',\n",
       "   'value': 'column1 = 10',\n",
       "   'children': [{'type': 'Identifier',\n",
       "     'value': 'column1',\n",
       "     'children': [{'type': Token.Name, 'value': 'column1'}]},\n",
       "    {'type': Token.Operator.Comparison, 'value': '='},\n",
       "    {'type': Token.Literal.Number.Integer, 'value': '10'}]}]}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.tree_to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATE\n",
      "has_ancestor: <bound method Token.has_ancestor of <DML 'UPDATE' at 0x7F7E8D9660A0>>\n",
      "ttype: Token.Keyword.DML\n",
      "is_group: False\n",
      "<class 'sqlparse.sql.Token'>\n",
      "\n",
      " \n",
      "has_ancestor: <bound method Token.has_ancestor of <Whitespace ' ' at 0x7F7E8D9661C0>>\n",
      "ttype: Token.Text.Whitespace\n",
      "is_group: False\n",
      "<class 'sqlparse.sql.Token'>\n",
      "\n",
      "TABLE\n",
      "has_ancestor: <bound method Token.has_ancestor of <Keyword 'TABLE' at 0x7F7E8D957B80>>\n",
      "ttype: Token.Keyword\n",
      "is_group: False\n",
      "<class 'sqlparse.sql.Token'>\n",
      "\n",
      "\n",
      "\n",
      "has_ancestor: <bound method Token.has_ancestor of <Newline ' ' at 0x7F7E8D957460>>\n",
      "ttype: Token.Text.Whitespace.Newline\n",
      "is_group: False\n",
      "<class 'sqlparse.sql.Token'>\n",
      "\n",
      "SET\n",
      "has_ancestor: <bound method Token.has_ancestor of <Keyword 'SET' at 0x7F7E8D957E80>>\n",
      "ttype: Token.Keyword\n",
      "is_group: False\n",
      "<class 'sqlparse.sql.Token'>\n",
      "\n",
      " \n",
      "has_ancestor: <bound method Token.has_ancestor of <Whitespace ' ' at 0x7F7E8D957EE0>>\n",
      "ttype: Token.Text.Whitespace\n",
      "is_group: False\n",
      "<class 'sqlparse.sql.Token'>\n",
      "\n",
      "column1 = 10\n",
      "has_ancestor: <bound method Token.has_ancestor of <Comparison 'column...' at 0x7F7E8D95F4A0>>\n",
      "get_sublists: <bound method TokenList.get_sublists of <Comparison 'column...' at 0x7F7E8D95F4A0>>\n",
      "ttype: None\n",
      "tokens: [<Identifier 'column1' at 0x7F7E8D95F430>, <Whitespace ' ' at 0x7F7E8D957F40>, <Comparison '=' at 0x7F7E8D957820>, <Whitespace ' ' at 0x7F7E8D957A00>, <Integer '10' at 0x7F7E8D733880>]\n",
      "is_group: True\n",
      "<class 'sqlparse.sql.Comparison'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for token in query.tree:\n",
    "    print(token)\n",
    "    try:\n",
    "        print(f\"has_ancestor: {token.has_ancestor}\")\n",
    "    except: pass\n",
    "    try:\n",
    "        print(f\"get_sublists: {token.get_sublists}\")\n",
    "    except:\n",
    "        pass\n",
    "    print(f\"ttype: {token.ttype}\")\n",
    "   \n",
    "    try:\n",
    "        print(f\"tokens: {token.tokens}\")\n",
    "    except: pass\n",
    "    # print(f\"token_first: {token.token_first}\")\n",
    "    # print(f\"token_next: {token.token_next}\")\n",
    "    # print(f\"token_prev: {token.token_prev}\")\n",
    "    print(f\"is_group: {token.is_group}\")\n",
    "    print(type(token))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UPDATE', ' ', 'TABLE', '\\n', 'SET', ' ', 'column1', ' ', '=', ' ', '10']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.flatten_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UPDATE table SET column1 = 10'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"UPDATE table SET column1 = 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "isinstance() arg 2 must be a type or tuple of types",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_to_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36mSqlQuery.tree_to_dict\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: token\u001b[38;5;241m.\u001b[39mttype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: token\u001b[38;5;241m.\u001b[39mnormalized}\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROOT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchildren\u001b[39m\u001b[38;5;124m\"\u001b[39m: [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m [process_token(token) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens] \u001b[38;5;28;01mif\u001b[39;00m c]}\n",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: token\u001b[38;5;241m.\u001b[39mttype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: token\u001b[38;5;241m.\u001b[39mnormalized}\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROOT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchildren\u001b[39m\u001b[38;5;124m\"\u001b[39m: [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m [\u001b[43mprocess_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens] \u001b[38;5;28;01mif\u001b[39;00m c]}\n",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36mSqlQuery.tree_to_dict.<locals>.process_token\u001b[0;34m(token)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIdentifier\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: token\u001b[38;5;241m.\u001b[39mnormalized}\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token, TokenList):\n\u001b[0;32m--> 165\u001b[0m     children \u001b[38;5;241m=\u001b[39m [process_token(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m token\u001b[38;5;241m.\u001b[39mtokens \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, Whitespace)]\n\u001b[1;32m    166\u001b[0m     token_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(token)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Special handling for IdentifierList, Function, and Comparison\u001b[39;00m\n",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIdentifier\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: token\u001b[38;5;241m.\u001b[39mnormalized}\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token, TokenList):\n\u001b[0;32m--> 165\u001b[0m     children \u001b[38;5;241m=\u001b[39m [process_token(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m token\u001b[38;5;241m.\u001b[39mtokens \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWhitespace\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    166\u001b[0m     token_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(token)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Special handling for IdentifierList, Function, and Comparison\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: isinstance() arg 2 must be a type or tuple of types"
     ]
    }
   ],
   "source": [
    "query.tree_to_dict() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<DML 'SELECT' at 0x7F7E8C11FC40>,\n",
       " <Whitespace ' ' at 0x7F7E8C11FE80>,\n",
       " <Wildcard '*' at 0x7F7E8C11FEE0>,\n",
       " <Newline ' ' at 0x7F7E8C11FF40>,\n",
       " <Keyword 'FROM' at 0x7F7E8C11FFA0>,\n",
       " <Whitespace ' ' at 0x7F7E8C11E040>,\n",
       " <Identifier 'users' at 0x7F7E8C120430>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"SELECT * FROM users\"\n",
    "sql_query = SqlQuery(query)\n",
    "sql_query.create_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'ROOT',\n",
       " 'children': [{'type': Token.Keyword.DML, 'value': 'SELECT'},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "  {'type': Token.Wildcard, 'value': '*'},\n",
       "  {'type': Token.Text.Whitespace.Newline, 'value': '\\n'},\n",
       "  {'type': Token.Keyword, 'value': 'FROM'},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "  {'type': 'TokenList',\n",
       "   'value': 'users',\n",
       "   'children': [{'type': Token.Name, 'value': 'users'}]}]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query.tree_to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Identifier 'users' at 0x7F7E8C120430>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query.tree[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tree_to_dict_select():\n",
    "    query = \"SELECT * FROM users\"\n",
    "    expected_dict = {\n",
    "        \"type\": \"ROOT\",\n",
    "        \"children\": [\n",
    "            {\"type\": sqlparse.tokens.DML, \"value\": \"SELECT\"},\n",
    "            {\"type\": sqlparse.tokens.Wildcard, \"value\": \"*\"},\n",
    "            {\"type\": sqlparse.tokens.Keyword, \"value\": \"FROM\"},\n",
    "            {\"type\": None, \"value\": \"users\"}\n",
    "        ]\n",
    "    }\n",
    "    sql_query = SqlQuery(query)\n",
    "    sql_query.create_tree()\n",
    "    print(sql_query.tree_to_dict())\n",
    "    print(expected_dict)\n",
    "    # assert sql_query.tree_to_dict() == expected_dict, \"Failed tree to dict for SELECT query\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'ROOT', 'children': [{'type': Token.Keyword.DML, 'value': 'SELECT'}, {'type': Token.Text.Whitespace, 'value': ' '}, {'type': Token.Wildcard, 'value': '*'}, {'type': Token.Text.Whitespace.Newline, 'value': '\\n'}, {'type': Token.Keyword, 'value': 'FROM'}, {'type': Token.Text.Whitespace, 'value': ' '}, {'type': 'TokenList', 'value': 'users', 'children': [{'type': Token.Name, 'value': 'users'}]}]}\n",
      "{'type': 'ROOT', 'children': [{'type': Token.Keyword.DML, 'value': 'SELECT'}, {'type': Token.Wildcard, 'value': '*'}, {'type': Token.Keyword, 'value': 'FROM'}, {'type': None, 'value': 'users'}]}\n"
     ]
    }
   ],
   "source": [
    "test_tree_to_dict_select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tree_to_dict_select():\n",
    "    query = \"SELECT * FROM users\"\n",
    "    expected_dict = {\n",
    "        \"type\": \"ROOT\",\n",
    "        \"children\": [\n",
    "            {\"type\": sqlparse.tokens.DML, \"value\": \"SELECT\", \"children\": []},\n",
    "            {\"type\": sqlparse.tokens.Whitespace, \"value\": \" \", \"children\": []},\n",
    "            {\"type\": sqlparse.tokens.Wildcard, \"value\": \"*\", \"children\": []},\n",
    "            {\"type\": sqlparse.tokens.Whitespace, \"value\": \" \", \"children\": []},\n",
    "            {\"type\": sqlparse.tokens.Keyword, \"value\": \"FROM\", \"children\": []},\n",
    "            {\"type\": sqlparse.tokens.Whitespace, \"value\": \" \", \"children\": []},\n",
    "            {\"type\": None, \"value\": \"users\", \"children\": []}\n",
    "        ]\n",
    "    }\n",
    "    sql_query = SqlQuery(query)\n",
    "    sql_query.create_tree()\n",
    "    print(sql_query.tree_to_dict())\n",
    "    # print(expected_dict)\n",
    "    # assert sql_query.tree_to_dict() == expected_dict, \"Failed tree to dict for SELECT query\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'ROOT', 'children': [{'type': Token.Keyword.DML, 'value': 'SELECT'}, {'type': Token.Text.Whitespace, 'value': ' '}, {'type': Token.Wildcard, 'value': '*'}, {'type': Token.Text.Whitespace.Newline, 'value': '\\n'}, {'type': Token.Keyword, 'value': 'FROM'}, {'type': Token.Text.Whitespace, 'value': ' '}, {'type': 'TokenList', 'value': 'users', 'children': [{'type': Token.Name, 'value': 'users'}]}]}\n"
     ]
    }
   ],
   "source": [
    "test_tree_to_dict_select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_cases.py\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        \"query\": \"UPDATE table SET column1 = 10\",\n",
    "        \"expected\": {\n",
    "            \"type\": \"ROOT\",\n",
    "            \"children\": [\n",
    "                {\"type\": \"DML\", \"value\": \"UPDATE\", \"is_group\": False},\n",
    "                {\"type\": \"Identifier\", \"value\": \"table\", \"is_group\": False},\n",
    "                {\"type\": \"Keyword\", \"value\": \"SET\", \"is_group\": False},\n",
    "                {\"type\": \"Identifier\", \"value\": \"column1\", \"is_group\": False},\n",
    "                {\"type\": \"Comparison\", \"value\": \"= 10\", \"is_group\": False}\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"SELECT column FROM table\",\n",
    "        \"expected\": {\n",
    "            \"type\": \"ROOT\",\n",
    "            \"children\": [\n",
    "                {\"type\": \"DML\", \"value\": \"SELECT\", \"is_group\": False},\n",
    "                {\"type\": \"Identifier\", \"value\": \"column\", \"is_group\": False},\n",
    "                {\"type\": \"Keyword\", \"value\": \"FROM\", \"is_group\": False},\n",
    "                {\"type\": \"Identifier\", \"value\": \"table\", \"is_group\": False}\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"SELECT * FROM users\",\n",
    "        \"expected\": {\n",
    "            \"type\": \"ROOT\",\n",
    "            \"children\": [\n",
    "                {\"type\": \"DML\", \"value\": \"SELECT\", \"is_group\": False},\n",
    "                {\"type\": \"Wildcard\", \"value\": \"*\", \"is_group\": False},\n",
    "                {\"type\": \"Keyword\", \"value\": \"FROM\", \"is_group\": False},\n",
    "                {\"type\": \"Identifier\", \"value\": \"users\", \"is_group\": False}\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"SELECT name, age FROM People WHERE age > 30\",\n",
    "        \"expected\": {\n",
    "            \"type\": \"ROOT\",\n",
    "            \"children\": [\n",
    "                {\"type\": \"DML\", \"value\": \"SELECT\", \"is_group\": False},\n",
    "                {\"type\": \"IdentifierList\", \"value\": \"name, age\", \"is_group\": True, \"children\": [\n",
    "                    {\"type\": \"Identifier\", \"value\": \"name\", \"is_group\": False},\n",
    "                    {\"type\": \"Identifier\", \"value\": \"age\", \"is_group\": False}\n",
    "                ]},\n",
    "                {\"type\": \"Keyword\", \"value\": \"FROM\", \"is_group\": False},\n",
    "                {\"type\": \"Identifier\", \"value\": \"People\", \"is_group\": False},\n",
    "                {\"type\": \"Where\", \"value\": \"WHERE age > 30\", \"is_group\": True, \"children\": [\n",
    "                    {\"type\": \"Comparison\", \"value\": \"age > 30\", \"is_group\": False}\n",
    "                ]}\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "\n",
    "{\n",
    "    \"query\": \"\"\"\n",
    "        SELECT u.id, \n",
    "               (SELECT COUNT(*) FROM orders WHERE orders.user_id = u.id) as order_count,\n",
    "               (SELECT AVG(amount) FROM payments WHERE payments.user_id = u.id) as average_payment\n",
    "        FROM users u \n",
    "        WHERE u.registration_date BETWEEN '2020-01-01' AND '2020-12-31'\n",
    "        AND (u.status = 'active' OR u.id IN (SELECT user_id FROM vip_users));\n",
    "    \"\"\",\n",
    "    \"expected\": {\n",
    "        \"type\": \"ROOT\",\n",
    "        \"children\": [\n",
    "            {\"type\": \"DML\", \"value\": \"SELECT\", \"is_group\": False},\n",
    "            {\"type\": \"Identifier\", \"value\": \"u.id\", \"is_group\": False},\n",
    "            {\"type\": \"Subselect\", \"value\": \"(SELECT COUNT(*) FROM orders WHERE orders.user_id = u.id)\", \"is_group\": True, \"children\": [\n",
    "                {\"type\": \"DML\", \"value\": \"SELECT\", \"is_group\": False},\n",
    "                {\"type\": \"Function\", \"value\": \"COUNT(*)\", \"is_group\": False},\n",
    "                {\"type\": \"Keyword\", \"value\": \"FROM\", \"is_group\": False},\n",
    "                {\"type\": \"Identifier\", \"value\": \"orders\", \"is_group\": False},\n",
    "                {\"type\": \"Where\", \"value\": \"WHERE orders.user_id = u.id\", \"is_group\": True, \"children\": [\n",
    "                    {\"type\": \"Comparison\", \"value\": \"orders.user_id = u.id\", \"is_group\": False}\n",
    "                ]}\n",
    "            ]},\n",
    "            {\"type\": \"Subselect\", \"value\": \"(SELECT AVG(amount) FROM payments WHERE payments.user_id = u.id)\", \"is_group\": True, \"children\": [\n",
    "                {\"type\": \"DML\", \"value\": \"SELECT\", \"is_group\": False},\n",
    "                {\"type\": \"Function\", \"value\": \"AVG(amount)\", \"is_group\": False},\n",
    "                {\"type\": \"Keyword\", \"value\": \"FROM\", \"is_group\": False},\n",
    "                {\"type\": \"Identifier\", \"value\": \"payments\", \"is_group\": False},\n",
    "                {\"type\": \"Where\", \"value\": \"WHERE payments.user_id = u.id\", \"is_group\": True, \"children\": [\n",
    "                    {\"type\": \"Comparison\", \"value\": \"payments.user_id = u.id\", \"is_group\": False}\n",
    "                ]}\n",
    "            ]},\n",
    "            {\"type\": \"Keyword\", \"value\": \"FROM\", \"is_group\": False},\n",
    "            {\"type\": \"Identifier\", \"value\": \"users u\", \"is_group\": False},\n",
    "            {\"type\": \"Where\", \"value\": \"WHERE u.registration_date BETWEEN '2020-01-01' AND '2020-12-31' AND (u.status = 'active' OR u.id IN (SELECT user_id FROM vip_users))\", \"is_group\": True, \"children\": [\n",
    "                {\"type\": \"Comparison\", \"value\": \"u.registration_date BETWEEN '2020-01-01' AND '2020-12-31'\", \"is_group\": False},\n",
    "                {\"type\": \"Boolean\", \"value\": \"AND\", \"is_group\": False},\n",
    "                {\"type\": \"Parenthesis\", \"value\": \"(u.status = 'active' OR u.id IN (SELECT user_id FROM vip_users))\", \"is_group\": True, \"children\": [\n",
    "                    {\"type\": \"Comparison\", \"value\": \"u.status = 'active'\", \"is_group\": False},\n",
    "                    {\"type\": \"Boolean\", \"value\": \"OR\", \"is_group\": False},\n",
    "                    {\"type\": \"Subselect\", \"value\": \"(SELECT user_id FROM vip_users)\", \"is_group\": True, \"children\": [\n",
    "                        {\"type\": \"DML\", \"value\": \"SELECT\", \"is_group\": False},\n",
    "                        {\"type\": \"Identifier\", \"value\": \"user_id\", \"is_group\": False},\n",
    "                        {\"type\": \"Keyword\", \"value\": \"FROM\", \"is_group\": False},\n",
    "                        {\"type\": \"Identifier\", \"value\": \"vip_users\", \"is_group\": False}\n",
    "                    ]}\n",
    "                ]}\n",
    "            ]}\n",
    "        ]\n",
    "    }\n",
    "},\n",
    "\n",
    "\n",
    "\n",
    "    {\n",
    "       \"query\": \"\"\"\n",
    "        WITH cte AS (\n",
    "            SELECT col1 FROM table1\n",
    "            UNION\n",
    "            SELECT col2 FROM table2\n",
    "        )\n",
    "        SELECT * FROM cte\n",
    "    \"\"\",\n",
    "    \"expected\": {\n",
    "        \"type\": \"ROOT\",\n",
    "        \"children\": [\n",
    "            {\"type\": \"CTE\", \"value\": \"WITH\", \"is_group\": True, \"children\": [\n",
    "                {\"type\": \"Identifier\", \"value\": \"cte\", \"is_group\": False},\n",
    "                {\"type\": \"Keyword\", \"value\": \"AS\", \"is_group\": False},\n",
    "                {\"type\": \"Subselect\", \"value\": \"(...)\", \"is_group\": True, \"children\": [\n",
    "                    {\"type\": \"DML\", \"value\": \"SELECT\", \"is_group\": False},\n",
    "                    {\"type\": \"Identifier\", \"value\": \"col1\", \"is_group\": False},\n",
    "                    {\"type\": \"Keyword\", \"value\": \"FROM\", \"is_group\": False},\n",
    "                    {\"type\": \"Identifier\", \"value\": \"table1\", \"is_group\": False},\n",
    "                    {\"type\": \"SetOperation\", \"value\": \"UNION\", \"is_group\": False},\n",
    "                    {\"type\": \"DML\", \"value\": \"SELECT\", \"is_group\": False},\n",
    "                    {\"type\": \"Identifier\", \"value\": \"col2\", \"is_group\": False},\n",
    "                    {\"type\": \"Keyword\", \"value\": \"FROM\", \"is_group\": False},\n",
    "                    {\"type\": \"Identifier\", \"value\": \"table2\", \"is_group\": False}\n",
    "                ]}\n",
    "            ]},\n",
    "            {\"type\": \"DML\", \"value\": \"SELECT\", \"is_group\": False},\n",
    "            {\"type\": \"Wildcard\", \"value\": \"*\", \"is_group\": False},\n",
    "            {\"type\": \"Keyword\", \"value\": \"FROM\", \"is_group\": False},\n",
    "            {\"type\": \"Identifier\", \"value\": \"cte\", \"is_group\": False}\n",
    "        ]\n",
    "    }\n",
    "    },\n",
    "    # Additional test cases can be added here\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATE table SET column1 = 10\n",
      "SELECT column FROM table\n",
      "SELECT * FROM users\n",
      "SELECT name, age FROM People WHERE age > 30\n",
      "\n",
      "        SELECT u.id, \n",
      "               (SELECT COUNT(*) FROM orders WHERE orders.user_id = u.id) as order_count,\n",
      "               (SELECT AVG(amount) FROM payments WHERE payments.user_id = u.id) as average_payment\n",
      "        FROM users u \n",
      "        WHERE u.registration_date BETWEEN '2020-01-01' AND '2020-12-31'\n",
      "        AND (u.status = 'active' OR u.id IN (SELECT user_id FROM vip_users));\n",
      "    \n",
      "\n",
      "        WITH cte AS (\n",
      "            SELECT col1 FROM table1\n",
      "            UNION\n",
      "            SELECT col2 FROM table2\n",
      "        )\n",
      "        SELECT * FROM cte\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for i in test_cases:\n",
    "    print(i['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPDATE table SET column1 = 10\n",
    "SELECT column FROM table\n",
    "SELECT * FROM users\n",
    "SELECT name, age FROM People WHERE age > 30\n",
    "\n",
    "SELECT u.id, (SELECT COUNT(*) FROM orders WHERE orders.user_id = u.id) as order_count, (SELECT AVG(amount) FROM payments WHERE payments.user_id = u.id) as average_payment\n",
    "FROM users u \n",
    "WHERE u.registration_date BETWEEN '2020-01-01' AND '2020-12-31'\n",
    "AND (u.status = 'active' OR u.id IN (SELECT user_id FROM vip_users));\n",
    "\n",
    "WITH cte AS (\n",
    "    SELECT col1 FROM table1\n",
    "    UNION\n",
    "    SELECT col2 FROM table2\n",
    ")\n",
    "SELECT * FROM cte"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "luc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
