{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sqlparse\n",
    "from sqlparse.sql import Token, TokenList, IdentifierList, Identifier, Function, Comparison\n",
    "from sqlparse.tokens import DML, Whitespace, Keyword, Name, Literal\n",
    "\n",
    "from typing import List, Dict, Union, Optional\n",
    "from functools import lru_cache\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up basic logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger __main__ (INFO)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_queries = [\n",
    "    \"UPDATE table SET column1 = 10\",\n",
    "    \"SELECT column FROM table\",\n",
    "    \"\"\"SELECT table.column1, table2.column2 FROM table JOIN (SELECT column2 FROM newtable) table2 ON table.column3 = table2.column3\"\"\",\n",
    "    \"\"\"\n",
    "    SELECT u.id, \n",
    "           (SELECT COUNT(*) FROM orders WHERE orders.user_id = u.id) as order_count,\n",
    "           (SELECT AVG(amount) FROM payments WHERE payments.user_id = u.id) as average_payment\n",
    "    FROM users u \n",
    "    WHERE u.registration_date BETWEEN '2020-01-01' AND '2020-12-31'\n",
    "    AND (u.status = 'active' OR u.id IN (SELECT user_id FROM vip_users));\"\"\"\n",
    "    ,\n",
    "    \"\"\"SELECT u.id\n",
    "    FROM users (select * from (select * from table))\"\"\",\n",
    "    \"ALTER TABLE table_name ADD column_name\",\n",
    "    \"\"\"\n",
    "    SELECT * FROM (\n",
    "        SELECT col1 FROM table1\n",
    "        UNION\n",
    "        SELECT col2 FROM table2\n",
    "    ) AS subquery\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    WITH cte AS (\n",
    "        SELECT col1 FROM table1\n",
    "        UNION\n",
    "        SELECT col2 FROM table2\n",
    "    )\n",
    "    SELECT * FROM cte\n",
    "    \"\"\",\n",
    "    \"SELECT *    FROM    my_table WHERE   id = 1\"\n",
    "    \n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqlQuery:\n",
    "    def __init__(self, query: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize the SqlQuery class with an optional SQL query.\n",
    "\n",
    "        :param query: Raw SQL query string.\n",
    "        \"\"\"\n",
    "        self.raw_query = query\n",
    "        self.normalized_query = self._normalize_query(query) if query else None\n",
    "        self.tree: Optional[List[Token]] = None\n",
    "        self.parsed_query: Optional[TokenList] = None\n",
    "\n",
    "    def _normalize_query(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        Normalizes the SQL query by formatting.\n",
    "\n",
    "        :param query: Raw SQL query string.\n",
    "        :return: Normalized SQL query string.\n",
    "        \"\"\"\n",
    "        return sqlparse.format(query, reindent=True, keyword_case='upper', strip_whitespace=True) if query else ''\n",
    "\n",
    "    def set_query(self, query: str, normalize: bool = True):\n",
    "        \"\"\"\n",
    "        Sets a new SQL query and optionally normalizes it.\n",
    "\n",
    "        :param query: Raw SQL query string.\n",
    "        :param normalize: Boolean flag to normalize the query.\n",
    "        \"\"\"\n",
    "        self.raw_query = query\n",
    "        self.normalized_query = self._normalize_query(query) if normalize else query\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def create_tree(self) -> List[Token]:\n",
    "        \"\"\"\n",
    "        Parses the SQL query (normalized, if available) and creates a parse tree.\n",
    "\n",
    "        :return: List of Tokens representing the parse tree.\n",
    "        \"\"\"\n",
    "        query_to_parse = self.normalized_query if self.normalized_query else self.raw_query\n",
    "        if not query_to_parse:\n",
    "            logger.error(\"No query set\")\n",
    "            raise ValueError(\"No query set\")\n",
    "\n",
    "        try:\n",
    "            parsed = sqlparse.parse(query_to_parse)\n",
    "            if not parsed:\n",
    "                logger.error(\"Failed to parse the query\")\n",
    "                raise ValueError(\"Failed to parse the query\")\n",
    "\n",
    "            self.parsed_query = parsed[0]\n",
    "            self.tree = self.parsed_query.tokens\n",
    "            return self.tree\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error while parsing the query: {e}\")\n",
    "            raise\n",
    "\n",
    "    def flatten_tree(self, tokens: Optional[List[Token]] = None) -> List[str]:\n",
    "        \"\"\"\n",
    "        Flattens the parse tree to a list of token strings.\n",
    "\n",
    "        :param tokens: Optional list of tokens to flatten.\n",
    "        :return: List of strings representing flattened tokens.\n",
    "        \"\"\"\n",
    "        if tokens is None:\n",
    "            tokens = self.tree\n",
    "\n",
    "        if tokens is None:\n",
    "            logger.error(\"Parse tree is not set\")\n",
    "            raise ValueError(\"Parse tree is not set\")\n",
    "\n",
    "        flat_tokens = []\n",
    "        for token in tokens:\n",
    "            if isinstance(token, TokenList):\n",
    "                flat_tokens.extend(self.flatten_tree(token.tokens))\n",
    "            else:\n",
    "                flat_tokens.append(token.normalized)\n",
    "        return flat_tokens\n",
    "\n",
    "    def is_read_only(self) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if the set query is read-only (SELECT).\n",
    "\n",
    "        :return: Boolean indicating if the query is read-only.\n",
    "        \"\"\"\n",
    "        if not self.tree:\n",
    "            logger.error(\"Parse tree is not set\")\n",
    "            raise ValueError(\"Parse tree is not set\")\n",
    "\n",
    "        modifying_keywords = [\"INSERT\", \"UPDATE\", \"DELETE\", \"DROP\", \"ALTER\"]\n",
    "        flat_tokens = self.flatten_tree()\n",
    "        return not any(keyword in flat_tokens for keyword in modifying_keywords)\n",
    "\n",
    "    def process_token(self, token) -> Union[Dict, str, None]:\n",
    "        \"\"\"\n",
    "        Process a single SQL token into a dictionary representation.\n",
    "\n",
    "        :param token: The SQL token to process.\n",
    "        :return: A dictionary representation of the token, or None for whitespace.\n",
    "        \"\"\"\n",
    "        if token.is_group:\n",
    "            # children = [self.process_token(child) for child in token.tokens if child.ttype is not Whitespace]\n",
    "            children = [self.process_token(child) for child in token.tokens]\n",
    "            return {\n",
    "                \"type\": type(token).__name__,\n",
    "                \"value\": token.normalized,\n",
    "                \"children\": [c for c in children if c]\n",
    "            }\n",
    "        else:\n",
    "            # if token.ttype is Whitespace:\n",
    "            #     return None\n",
    "            return {\n",
    "                \"type\": token.ttype,\n",
    "                \"value\": token.normalized\n",
    "            }\n",
    "\n",
    "    def tree_to_dict(self, tokens=None) -> Dict:\n",
    "        \"\"\"\n",
    "        Converts a list of SQL tokens to a nested dictionary representation.\n",
    "\n",
    "        :param tokens: List of SQL tokens.\n",
    "        :return: Nested dictionary representing the SQL tokens.\n",
    "        \"\"\"\n",
    "        if tokens is None:\n",
    "            tokens = self.tree\n",
    "\n",
    "        return {\"type\": \"ROOT\", \"children\": [self.process_token(token) for token in tokens if self.process_token(token)]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = SqlQuery(query=sql_queries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<DML 'UPDATE' at 0x7F7E8DA2C340>,\n",
       " <Whitespace ' ' at 0x7F7E8DBD7FA0>,\n",
       " <Keyword 'TABLE' at 0x7F7E8DBBCC40>,\n",
       " <Newline ' ' at 0x7F7E8DAB5820>,\n",
       " <Keyword 'SET' at 0x7F7E8DAB5A00>,\n",
       " <Whitespace ' ' at 0x7F7E8DAB59A0>,\n",
       " <Comparison 'column...' at 0x7F7E8DBC6B30>]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.create_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'ROOT',\n",
       " 'children': [{'type': Token.Keyword.DML, 'value': 'UPDATE'},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "  {'type': Token.Keyword, 'value': 'TABLE'},\n",
       "  {'type': Token.Text.Whitespace.Newline, 'value': '\\n'},\n",
       "  {'type': Token.Keyword, 'value': 'SET'},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "  {'type': 'Comparison',\n",
       "   'value': 'column1 = 10',\n",
       "   'children': [{'type': 'Identifier',\n",
       "     'value': 'column1',\n",
       "     'children': [{'type': Token.Name, 'value': 'column1'}]},\n",
       "    {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "    {'type': Token.Operator.Comparison, 'value': '='},\n",
       "    {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "    {'type': Token.Literal.Number.Integer, 'value': '10'}]}]}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.tree_to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'ROOT',\n",
       " 'children': [{'type': Token.Keyword.DML, 'value': 'UPDATE'},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "  {'type': Token.Keyword, 'value': 'TABLE'},\n",
       "  {'type': Token.Text.Whitespace.Newline, 'value': '\\n'},\n",
       "  {'type': Token.Keyword, 'value': 'SET'},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "  {'type': 'Comparison',\n",
       "   'value': 'column1 = 10',\n",
       "   'children': [{'type': 'Identifier',\n",
       "     'value': 'column1',\n",
       "     'children': [{'type': Token.Name, 'value': 'column1'}]},\n",
       "    {'type': Token.Operator.Comparison, 'value': '='},\n",
       "    {'type': Token.Literal.Number.Integer, 'value': '10'}]}]}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.tree_to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATE\n",
      "has_ancestor: <bound method Token.has_ancestor of <DML 'UPDATE' at 0x7F7E8D9660A0>>\n",
      "ttype: Token.Keyword.DML\n",
      "is_group: False\n",
      "<class 'sqlparse.sql.Token'>\n",
      "\n",
      " \n",
      "has_ancestor: <bound method Token.has_ancestor of <Whitespace ' ' at 0x7F7E8D9661C0>>\n",
      "ttype: Token.Text.Whitespace\n",
      "is_group: False\n",
      "<class 'sqlparse.sql.Token'>\n",
      "\n",
      "TABLE\n",
      "has_ancestor: <bound method Token.has_ancestor of <Keyword 'TABLE' at 0x7F7E8D957B80>>\n",
      "ttype: Token.Keyword\n",
      "is_group: False\n",
      "<class 'sqlparse.sql.Token'>\n",
      "\n",
      "\n",
      "\n",
      "has_ancestor: <bound method Token.has_ancestor of <Newline ' ' at 0x7F7E8D957460>>\n",
      "ttype: Token.Text.Whitespace.Newline\n",
      "is_group: False\n",
      "<class 'sqlparse.sql.Token'>\n",
      "\n",
      "SET\n",
      "has_ancestor: <bound method Token.has_ancestor of <Keyword 'SET' at 0x7F7E8D957E80>>\n",
      "ttype: Token.Keyword\n",
      "is_group: False\n",
      "<class 'sqlparse.sql.Token'>\n",
      "\n",
      " \n",
      "has_ancestor: <bound method Token.has_ancestor of <Whitespace ' ' at 0x7F7E8D957EE0>>\n",
      "ttype: Token.Text.Whitespace\n",
      "is_group: False\n",
      "<class 'sqlparse.sql.Token'>\n",
      "\n",
      "column1 = 10\n",
      "has_ancestor: <bound method Token.has_ancestor of <Comparison 'column...' at 0x7F7E8D95F4A0>>\n",
      "get_sublists: <bound method TokenList.get_sublists of <Comparison 'column...' at 0x7F7E8D95F4A0>>\n",
      "ttype: None\n",
      "tokens: [<Identifier 'column1' at 0x7F7E8D95F430>, <Whitespace ' ' at 0x7F7E8D957F40>, <Comparison '=' at 0x7F7E8D957820>, <Whitespace ' ' at 0x7F7E8D957A00>, <Integer '10' at 0x7F7E8D733880>]\n",
      "is_group: True\n",
      "<class 'sqlparse.sql.Comparison'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for token in query.tree:\n",
    "    print(token)\n",
    "    try:\n",
    "        print(f\"has_ancestor: {token.has_ancestor}\")\n",
    "    except: pass\n",
    "    try:\n",
    "        print(f\"get_sublists: {token.get_sublists}\")\n",
    "    except:\n",
    "        pass\n",
    "    print(f\"ttype: {token.ttype}\")\n",
    "   \n",
    "    try:\n",
    "        print(f\"tokens: {token.tokens}\")\n",
    "    except: pass\n",
    "    # print(f\"token_first: {token.token_first}\")\n",
    "    # print(f\"token_next: {token.token_next}\")\n",
    "    # print(f\"token_prev: {token.token_prev}\")\n",
    "    print(f\"is_group: {token.is_group}\")\n",
    "    print(type(token))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UPDATE', ' ', 'TABLE', '\\n', 'SET', ' ', 'column1', ' ', '=', ' ', '10']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.flatten_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UPDATE table SET column1 = 10'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"UPDATE table SET column1 = 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "isinstance() arg 2 must be a type or tuple of types",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_to_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36mSqlQuery.tree_to_dict\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: token\u001b[38;5;241m.\u001b[39mttype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: token\u001b[38;5;241m.\u001b[39mnormalized}\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROOT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchildren\u001b[39m\u001b[38;5;124m\"\u001b[39m: [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m [process_token(token) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens] \u001b[38;5;28;01mif\u001b[39;00m c]}\n",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: token\u001b[38;5;241m.\u001b[39mttype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: token\u001b[38;5;241m.\u001b[39mnormalized}\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROOT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchildren\u001b[39m\u001b[38;5;124m\"\u001b[39m: [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m [\u001b[43mprocess_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens] \u001b[38;5;28;01mif\u001b[39;00m c]}\n",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36mSqlQuery.tree_to_dict.<locals>.process_token\u001b[0;34m(token)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIdentifier\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: token\u001b[38;5;241m.\u001b[39mnormalized}\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token, TokenList):\n\u001b[0;32m--> 165\u001b[0m     children \u001b[38;5;241m=\u001b[39m [process_token(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m token\u001b[38;5;241m.\u001b[39mtokens \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, Whitespace)]\n\u001b[1;32m    166\u001b[0m     token_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(token)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Special handling for IdentifierList, Function, and Comparison\u001b[39;00m\n",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIdentifier\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: token\u001b[38;5;241m.\u001b[39mnormalized}\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token, TokenList):\n\u001b[0;32m--> 165\u001b[0m     children \u001b[38;5;241m=\u001b[39m [process_token(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m token\u001b[38;5;241m.\u001b[39mtokens \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWhitespace\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    166\u001b[0m     token_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(token)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Special handling for IdentifierList, Function, and Comparison\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: isinstance() arg 2 must be a type or tuple of types"
     ]
    }
   ],
   "source": [
    "query.tree_to_dict() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<DML 'SELECT' at 0x7F7E8C11FC40>,\n",
       " <Whitespace ' ' at 0x7F7E8C11FE80>,\n",
       " <Wildcard '*' at 0x7F7E8C11FEE0>,\n",
       " <Newline ' ' at 0x7F7E8C11FF40>,\n",
       " <Keyword 'FROM' at 0x7F7E8C11FFA0>,\n",
       " <Whitespace ' ' at 0x7F7E8C11E040>,\n",
       " <Identifier 'users' at 0x7F7E8C120430>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"SELECT * FROM users\"\n",
    "sql_query = SqlQuery(query)\n",
    "sql_query.create_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'ROOT',\n",
       " 'children': [{'type': Token.Keyword.DML, 'value': 'SELECT'},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "  {'type': Token.Wildcard, 'value': '*'},\n",
       "  {'type': Token.Text.Whitespace.Newline, 'value': '\\n'},\n",
       "  {'type': Token.Keyword, 'value': 'FROM'},\n",
       "  {'type': Token.Text.Whitespace, 'value': ' '},\n",
       "  {'type': 'TokenList',\n",
       "   'value': 'users',\n",
       "   'children': [{'type': Token.Name, 'value': 'users'}]}]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query.tree_to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Identifier 'users' at 0x7F7E8C120430>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query.tree[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tree_to_dict_select():\n",
    "    query = \"SELECT * FROM users\"\n",
    "    expected_dict = {\n",
    "        \"type\": \"ROOT\",\n",
    "        \"children\": [\n",
    "            {\"type\": sqlparse.tokens.DML, \"value\": \"SELECT\"},\n",
    "            {\"type\": sqlparse.tokens.Wildcard, \"value\": \"*\"},\n",
    "            {\"type\": sqlparse.tokens.Keyword, \"value\": \"FROM\"},\n",
    "            {\"type\": None, \"value\": \"users\"}\n",
    "        ]\n",
    "    }\n",
    "    sql_query = SqlQuery(query)\n",
    "    sql_query.create_tree()\n",
    "    print(sql_query.tree_to_dict())\n",
    "    print(expected_dict)\n",
    "    # assert sql_query.tree_to_dict() == expected_dict, \"Failed tree to dict for SELECT query\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'ROOT', 'children': [{'type': Token.Keyword.DML, 'value': 'SELECT'}, {'type': Token.Text.Whitespace, 'value': ' '}, {'type': Token.Wildcard, 'value': '*'}, {'type': Token.Text.Whitespace.Newline, 'value': '\\n'}, {'type': Token.Keyword, 'value': 'FROM'}, {'type': Token.Text.Whitespace, 'value': ' '}, {'type': 'TokenList', 'value': 'users', 'children': [{'type': Token.Name, 'value': 'users'}]}]}\n",
      "{'type': 'ROOT', 'children': [{'type': Token.Keyword.DML, 'value': 'SELECT'}, {'type': Token.Wildcard, 'value': '*'}, {'type': Token.Keyword, 'value': 'FROM'}, {'type': None, 'value': 'users'}]}\n"
     ]
    }
   ],
   "source": [
    "test_tree_to_dict_select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tree_to_dict_select():\n",
    "    query = \"SELECT * FROM users\"\n",
    "    expected_dict = {\n",
    "        \"type\": \"ROOT\",\n",
    "        \"children\": [\n",
    "            {\"type\": sqlparse.tokens.DML, \"value\": \"SELECT\", \"children\": []},\n",
    "            {\"type\": sqlparse.tokens.Whitespace, \"value\": \" \", \"children\": []},\n",
    "            {\"type\": sqlparse.tokens.Wildcard, \"value\": \"*\", \"children\": []},\n",
    "            {\"type\": sqlparse.tokens.Whitespace, \"value\": \" \", \"children\": []},\n",
    "            {\"type\": sqlparse.tokens.Keyword, \"value\": \"FROM\", \"children\": []},\n",
    "            {\"type\": sqlparse.tokens.Whitespace, \"value\": \" \", \"children\": []},\n",
    "            {\"type\": None, \"value\": \"users\", \"children\": []}\n",
    "        ]\n",
    "    }\n",
    "    sql_query = SqlQuery(query)\n",
    "    sql_query.create_tree()\n",
    "    print(sql_query.tree_to_dict())\n",
    "    # print(expected_dict)\n",
    "    # assert sql_query.tree_to_dict() == expected_dict, \"Failed tree to dict for SELECT query\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'ROOT', 'children': [{'type': Token.Keyword.DML, 'value': 'SELECT'}, {'type': Token.Text.Whitespace, 'value': ' '}, {'type': Token.Wildcard, 'value': '*'}, {'type': Token.Text.Whitespace.Newline, 'value': '\\n'}, {'type': Token.Keyword, 'value': 'FROM'}, {'type': Token.Text.Whitespace, 'value': ' '}, {'type': 'TokenList', 'value': 'users', 'children': [{'type': Token.Name, 'value': 'users'}]}]}\n"
     ]
    }
   ],
   "source": [
    "test_tree_to_dict_select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "luc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
